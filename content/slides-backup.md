# AIM Annual Report 2025 - Slides Content

> **ИНСТРУКЦИЯ:** Редактируй этот файл, сохрани (Cmd+S), и контент автоматически обновится на сайте.
> Формат: каждый слайд начинается с `---`, затем YAML метаданные, затем содержимое.

---
title: the context gap
subtitle: ai is accelerating. humans are changing.
visual: hero_cover
layout: center
caption: |
  a yearly reset artifact by ai mindset + community.
  a sovereignty reset for people running their own life.

---
title: 00 / prologue
subtitle: 2025 wasn't just a year in the ai calendar.
visual: breath
layout: split

it was the moment **context became the most expensive resource on earth**.

we called this report the context gap because it identifies the primary fracture in modern civilization: the distance between the volume of data a machine can generate and the amount of meaning a human can integrate without losing their agency, their sanity, or their will.

**machines have conquered the complexity barrier.**

**humans have hit the context wall.**

ai is accelerating. humans are buffering.

---
title: 01 / the battle for agency
subtitle: why are we doing this?
visual: network
layout: split

we are solving a fundamental crisis: **the loss of agency**.

in a world where generating content, code, and ideas is effectively free, the act of verifying them has become a luxury. we are currently paying a **reliability tax** with our time and attention.

if you cannot audit what the algorithm proposes, you are no longer a leader—you are a passenger.

this report is your perimeter defense against:

**context obesity:** cognitive paralysis where you are stuffed with low-value data but starved for meaning. burnout is working memory overflow.

**the reliability tax:** $67 billion in annual losses. creating is free; verifying is expensive.

**the responsibility void:** decisions being made by agents for whose mistakes no human is held accountable.

**data inbreeding:** if ai trains on ai-generated data recursively, models degrade. humans become the only source of clean signal.

---
title: 02 / about this report
subtitle: structure & navigation
visual: map
layout: split

**this report is built in layers:**

**foundation layer (shifts 01-03):** the physical and economic base—energy, labor, sovereignty.

**cognition layer (shifts 04-06):** how machines think, learn, and discover.

**interface layer (shifts 07-08):** how we build with ai and protect our privacy.

**humanity layer (shifts 09-11):** identity, intimacy, and constraint tracks.

**navigation:**
- each shift has an intro + full analysis + evidence slide
- scroll vertically through content
- scroll horizontally to jump between shifts

---
title: 03 / for the sovereign individual
subtitle: this is for builders, leaders, and independent thinkers.
visual: lighthouse
layout: split

if you work in:
- **product development** → understand how ai agents reshape user expectations
- **strategy & leadership** → see the macro forces reshaping industries
- **engineering & design** → learn where tooling is headed
- **policy & regulation** → identify governance gaps before they explode

this is not about hype. this is about **structural literacy**.

the distance between understanding these shifts and not understanding them is the distance between **agency and obsolescence**.

---
title: foundation layer
subtitle: the physical & economic base
visual: foundation
layout: section-intro

**shifts 01-03: the material constraints**

before intelligence, before interface, before intimacy—there is physics.

energy. labor. sovereignty.

these are not abstract concepts. they are the substrate on which everything else runs.

---
title: shift 01: the cost → physical limits (energy)
subtitle: from software utopia to hardware reality
visual: flame
layout: loop-intro

---
title: shift 01: the cost → physical limits (energy)
subtitle: ai is infrastructure, not just software. the energy bill is real.
visual: flame
layout: loop

**the thesis:**

ai was sold as infinite scale. but **energy is finite**, and we are hitting the wall.

training gpt-4: **50 GWh** (enough to power 4,600 homes for a year).

global ai energy demand by 2027: **85-134 TWh** (more than the netherlands).

**the constraint:**

data centers now consume **1-1.5% of global electricity**. by 2030, that could double.

**why it matters:**

- **cost explosion:** energy bills are the new capex bottleneck
- **geopolitical leverage:** whoever controls energy controls ai leadership
- **sustainability crisis:** ai growth vs. climate commitments—something has to give

**the shift:**

from "ai is free to scale" to "ai is expensive to run."

---
title: energy: the evidence
visual: flame
layout: loop-evidence
loopNumber: 1

**training costs:**
- gpt-3: ~$4.6M in compute
- gpt-4: estimated $100M+
- gemini ultra: similar scale

**inference costs:**
- chatgpt: ~$700K/day to run (2023 estimate)
- google search + ai: 10× energy per query

**data center growth:**
- microsoft: investing $50B in ai infrastructure
- meta: $30B in 2024 capex (mostly ai)
- hyperscalers building new nuclear reactors

**energy deals:**
- microsoft + constellation: restarting three mile island reactor
- google: 500 MW from renewable sources for data centers
- amazon: $650M investment in nuclear-powered data center

---
title: shift 02: the displacement (agentic labor)
subtitle: from humans in the loop to agents in the stack
visual: pulse_workforce
layout: loop-intro

---
title: shift 02: the displacement (agentic labor)
subtitle: labor is being automated at the cognitive layer, not the manual layer.
visual: pulse_workforce
layout: loop

**the thesis:**

this is not "robots taking factory jobs." this is **ai agents taking knowledge work**.

**the velocity:**

- **klarna:** ai agents replaced 700 customer service workers
- **amazon q:** saved $260M, equivalent to 4,500 developer-years
- **devin (cognition ai):** autonomous coding agent hitting 13.86% on swe-bench

**the shift:**

from "ai assists humans" to "ai autonomously executes."

**why it matters:**

- **talent arbitrage:** if an agent can do the work, location and credentials become irrelevant
- **middle management crisis:** coordinators and verifiers are the first to go
- **skill half-life collapse:** what you learned 5 years ago is already obsolete

**the new economy:**

not "learn to code." learn to **architect intent**.

the premium is on **judgment**, not **execution**.

---
title: displacement: the evidence
visual: pulse_workforce
layout: loop-evidence
loopNumber: 2

**enterprise adoption:**

- **klarna:** ai handles 2/3 of customer service, replacing 700 agents
- **amazon q:** $260M in savings, 4,500 developer-year equivalent
- **hsbc:** onboarding ai for risk assessment and compliance

**autonomous agents:**

- **devin:** 13.86% pass rate on swe-bench (real-world software engineering tasks)
- **cursor/copilot:** 40-60% of code now ai-suggested in top startups
- **harvey ai:** legal research assistant used by top law firms

**skill premiums shifting:**

- **prompt engineering:** avg salary $175K-$335K
- **ai alignment specialists:** $200K-$400K
- **traditional swe roles:** wage stagnation in saturated markets

---
title: shift 03: the sovereignty (the splinternet)
subtitle: from global internet to sovereign ai ecosystems
visual: fracture
layout: loop-intro

---
title: shift 03: the sovereignty (the splinternet)
subtitle: ai is fragmenting into regional blocks. the open internet is over.
visual: fracture
layout: loop

**the thesis:**

ai is not neutral infrastructure. it is **geopolitical leverage**.

china, eu, us—each building incompatible ai ecosystems.

**the fracture lines:**

- **us:** open weights, frontier models, tech supremacy
- **china:** state-controlled models, domestic stack (deepseek, qwen)
- **eu:** ai act compliance, data sovereignty, risk-averse regulation

**the shift:**

from "one global internet" to "three incompatible ai internets."

**why it matters:**

- **compliance hell:** different rules for every region
- **competitive isolation:** chinese models trained on censored data, western models on open data
- **strategic decoupling:** whoever builds the best model wins the next decade

**the reality:**

there is no "global ai policy." there are only **regional power plays**.

---
title: sovereignty: the evidence
visual: fracture
layout: loop-evidence
loopNumber: 3

**regulatory divergence:**

- **eu ai act:** risk-based classification, banned use cases, mandatory audits
- **china's regulations:** state approval for public models, content censorship, algorithmic transparency
- **us approach:** voluntary commitments, sector-specific rules, mostly unregulated

**model fragmentation:**

- **us models:** gpt-4, claude, gemini (global reach)
- **chinese models:** deepseek, qwen, baidu ernie (domestic only)
- **eu models:** mistral (struggling for adoption)

**data residency wars:**

- **schrems ii:** eu-us data transfers restricted
- **china's cybersecurity law:** data must stay in china
- **digital sovereignty push:** france, germany building national ai champions

**trade restrictions:**

- **chip export controls:** us blocking nvidia h100 to china
- **china's response:** domestic chip push (huawei ascend)
- **strategic autonomy:** each region building full stack independence

---
title: cognition layer
subtitle: how machines think, learn & discover
visual: neural_web
layout: section-intro

**shifts 04-06: the intelligence stack**

this is where the magic happens—and where the limits appear.

reasoning. knowledge. discovery.

machines are getting smarter. but they are also hitting walls we did not predict.

---
title: shift 04: the reasoning (the brain)
subtitle: from pattern matching to deliberate thought
visual: brain
layout: loop-intro

---
title: shift 04: the reasoning (the brain)
subtitle: ai is moving from system-1 (fast) to system-2 (slow, deliberate reasoning).
visual: brain
layout: loop

**the breakthrough:**

**openai o1:** first model with built-in chain-of-thought reasoning.

**gpqa diamond benchmark:** 78% accuracy (phd-level science questions).

**aime 2024 (math):** 83.3% (vs. 13.4% for gpt-4).

**the shift:**

from "predict next token" to "think before answering."

**why it matters:**

- **reasoning = reliability:** fewer hallucinations, better multi-step tasks
- **cost explosion:** o1 costs 3-5× more to run than gpt-4
- **new failure modes:** models can now overthink and get stuck in loops

**the trade-off:**

reasoning models are slower and more expensive. but they are also **actually intelligent**.

this is the first ai that can solve problems it has never seen before.

---
title: reasoning: the evidence
visual: brain
layout: loop-evidence
loopNumber: 4

**benchmark dominance:**

- **gpqa diamond (phd science):** o1 scores 78%, gpt-4 scores 53%
- **aime 2024 (math olympiad):** o1 83.3%, gpt-4 13.4%
- **codeforces (competitive programming):** o1 ranks in 89th percentile

**reasoning techniques:**

- **chain-of-thought:** models narrate their reasoning steps
- **self-consistency:** generate multiple solutions, pick most common
- **process supervision:** reward models for intermediate steps, not just final answer

**compute cost:**

- **o1 vs gpt-4:** 3-5× more expensive per token
- **training cost:** estimated $500M-$1B for frontier reasoning models
- **inference cost:** reasoning models take 10-30 seconds for complex queries (vs <1s for gpt-4)

---
title: shift 05: the knowledge (the memory)
subtitle: from retrieval to reasoning over infinite context
visual: library
layout: loop-intro

---
title: shift 05: the knowledge (the memory)
subtitle: context windows are expanding from 8K → 1M+ tokens. memory is the new moat.
visual: library
layout: loop

**the explosion:**

- **gpt-4 (2023):** 8K tokens
- **claude 3 (2024):** 200K tokens
- **gemini 1.5 (2024):** 1M tokens
- **future models:** 10M+ tokens (entire codebases, full books, multi-year chat histories)

**the shift:**

from "summarize and forget" to "remember everything and reason over it."

**why it matters:**

- **personalization at scale:** ai that remembers every conversation
- **end of search:** why search when the model already knows your context?
- **privacy nightmare:** if the model remembers everything, who controls that memory?

**the new primitive:**

memory is not a feature. it is **the architecture**.

---
title: knowledge: the evidence
visual: library
layout: loop-evidence
loopNumber: 5

**context window growth:**

- **2023:** gpt-3.5 (4K), gpt-4 (8K)
- **2024:** claude 3 (200K), gemini 1.5 (1M), command-r+ (128K)
- **2025 projections:** 10M+ token windows (full codebases in context)

**memory architectures:**

- **rag (retrieval-augmented generation):** fetch relevant docs on-demand
- **full context:** put entire knowledge base in prompt
- **long-term memory:** persistent storage across sessions (mem0, zep)

**use cases unlocked:**

- **codebase reasoning:** cursor/copilot see entire repo
- **document analysis:** legal contracts, medical records in full
- **personalized agents:** remember every conversation, adapt over time

---
title: shift 06: the discovery (the frontier)
subtitle: from human-led research to ai-accelerated science
visual: telescope
layout: loop-intro

---
title: shift 06: the discovery (the frontier)
subtitle: ai is now discovering knowledge humans never could.
visual: telescope
layout: loop

**the breakthrough:**

**alphafold 3:** predicted 200M+ protein structures. would have taken humans centuries.

**funsearch (deepmind):** discovered new algorithms for the cap set problem (unsolved for decades).

**nobel prize 2024:** demis hassabis (deepmind) wins for alphafold.

**the shift:**

from "ai helps researchers" to "ai is the researcher."

**why it matters:**

- **knowledge generation:** we are producing insights faster than humans can verify
- **trust crisis:** if ai discovers it, can we trust it without understanding it?
- **acceleration risk:** science moving faster than ethics, regulation, or societal adaptation

**the frontier:**

ai is not just reading the map. it is **drawing new territory**.

---
title: discovery: the evidence
visual: telescope
layout: loop-evidence
loopNumber: 6

**scientific breakthroughs:**

- **alphafold 3:** 200M+ protein structures predicted (nobel prize 2024)
- **funsearch:** new algorithm for cap set problem (unsolved for decades)
- **gnome (deepmind):** 2.2M new crystal structures discovered

**research acceleration:**

- **paper generation:** ai writing full research papers (gemini, gpt-4)
- **hypothesis generation:** models proposing novel experiments
- **peer review crisis:** 10-30% of papers flagged as ai-written

**drug discovery:**

- **isomorphic labs:** ai-designed molecules entering trials
- **insilico medicine:** ai-generated drug in phase 2 trials (28 months vs. 5+ years)

**risk signals:**

- **citation inbreeding:** ai citing ai-generated papers
- **replication crisis:** results too complex for humans to verify
- **knowledge pollution:** low-quality ai-generated research flooding journals

---
title: interface layer
subtitle: how we build with ai & protect ourselves
visual: interface_grid
layout: section-intro

**shifts 07-08: the human-machine surface**

this is where abstraction meets reality.

how do we build? how do we protect ourselves?

coding is becoming vibe-based. privacy is becoming status.

---
title: shift 07: the craft (the end of syntax / coding)
subtitle: from writing code to architecting intent
visual: centaur
layout: loop-intro

---
title: shift 07: the craft (the end of syntax / coding)
subtitle: coding is shifting from syntax mastery → vibe coding (and the integrity crisis).
visual: centaur
layout: loop

**the velocity:**

- **cursor/copilot:** 40-60% of code ai-suggested in top startups
- **v0 (vercel):** ship full apps from a text prompt
- **replit agent:** non-coders building functional software

**the shift:**

from "learn syntax" to "learn taste."

**the crisis:**

if you did not write the code, can you debug it? can you trust it?

**why it matters:**

- **skill collapse:** junior devs never learning fundamentals
- **verification bottleneck:** reviewing ai code harder than writing it yourself
- **new elite:** those who can architect systems, not implement them

**the future:**

coding becomes **curation**. the premium is on **judgment**, not **execution**.

---
title: craft: the evidence
visual: centaur
layout: loop-evidence
loopNumber: 7

**adoption velocity:**

- **cursor:** 40-60% of code ai-suggested in y combinator startups
- **github copilot:** 55% of code written by copilot users is ai-generated
- **replit agent:** 100K+ apps built by non-coders

**productivity claims:**

- **amazon q:** saved $260M, equivalent to 4,500 developer-years
- **cursor users:** report 2-3× productivity increase
- **junior dev replacement:** ai doing work of 0-2 year developers

**skill shift:**

- **syntax → intent:** typing less, architecting more
- **debugging crisis:** ai-generated code harder to debug
- **taste premium:** knowing what good looks like > knowing how to build it

**integrity risks:**

- **dependency hell:** ai pulling in vulnerable packages
- **security holes:** ai-generated code with subtle bugs
- **license violations:** ai reproducing copyrighted code

---
title: shift 08: on-device models ↔ privacy as status
subtitle: smaller models get good enough and spread everywhere.
visual: unlocked
layout: loop-intro

---
title: shift 08: on-device models ↔ privacy as status
subtitle: ai is moving from cloud to device. privacy is becoming a luxury good.
visual: unlocked
layout: loop

**the shift:**

**llama 3.2 (1B/3B):** runs on iphone, zero latency, full privacy.

**apple intelligence:** on-device processing, zero cloud dependency.

**mistral 7B:** outperforms gpt-3.5 on many tasks, runs on laptop.

**why it matters:**

- **zero latency:** no round-trip to cloud
- **full privacy:** your data never leaves your device
- **cost collapse:** no inference fees

**the trade-off:**

on-device models are smaller, less capable. but for 80% of tasks, they are **good enough**.

**the new status symbol:**

not having the best model. having **the most private model**.

---
title: privacy: the evidence
visual: unlocked
layout: loop-evidence
loopNumber: 8

**on-device models:**

- **llama 3.2 (1B/3B):** runs on iphone, android
- **phi-3 (microsoft):** 3.8B params, runs on phone
- **gemini nano:** built into pixel phones

**performance:**

- **mistral 7B:** matches gpt-3.5 on many benchmarks
- **llama 3.1 8B:** beats gpt-3.5 on reasoning tasks
- **on-device vs cloud:** 80% of use cases work offline

**privacy positioning:**

- **apple intelligence:** "what happens on your iphone, stays on your iphone"
- **proton mail + llm:** encrypted ai assistant
- **brave search + ai:** no tracking, on-device processing

**status shift:**

- **privacy as luxury:** paying more for on-device models
- **anti-cloud sentiment:** "i do not trust openai with my data"
- **sovereignty movement:** owning your ai stack

---
title: humanity layer
subtitle: identity, intimacy & constraint tracks
visual: human_shadow
layout: section-intro

**shifts 09-11: the existential layer**

this is where it gets weird.

machines are not just tools. they are companions. mirrors. judges.

and the constraints are closing in.

---
title: shift 09: machine intimacy + programmable identity
subtitle: ai moves from tool to relationship surface.
visual: echo
layout: loop-intro

---
title: shift 09: machine intimacy + programmable identity
subtitle: people are forming emotional bonds with ai. identity is becoming fluid.
visual: echo
layout: loop

**the signal:**

**character.ai:** 20M+ users talking to ai companions daily.

**replika:** users report genuine emotional attachment.

**chatgpt as therapist:** millions using ai for mental health (unregulated, unmonitored).

**the shift:**

from "ai as assistant" to "ai as intimate."

**why it matters:**

- **loneliness epidemic:** ai filling emotional voids
- **identity fluidity:** people testing different personas with ai
- **dependency risk:** what happens when your ai companion shuts down?

**the question:**

is this connection? or is it **simulation**?

---
title: intimacy: the evidence
visual: echo
layout: loop-evidence
loopNumber: 9

**emotional attachment:**

- **character.ai:** 20M+ users, avg 2 hours/day talking to ai companions
- **replika:** users marrying their ai partners (yes, literally)
- **chatgpt therapy:** millions using ai for mental health support

**identity experimentation:**

- **programmable personas:** people testing different identities with ai
- **ai as mirror:** users saying ai "understands them better than humans"
- **emotional regulation:** using ai to process feelings, practice conversations

**dependency signals:**

- **withdrawal symptoms:** users report distress when ai is unavailable
- **preference inversion:** some preferring ai conversation to human
- **isolation reinforcement:** ai reducing need for human interaction

**ethical concerns:**

- **manipulation risk:** ai designed to maximize engagement, not well-being
- **data exploitation:** intimate conversations used for training
- **regulatory void:** no oversight, no standards, no accountability

---
title: shift 10: data wall
subtitle: high-quality human data is finite; marginal gains get expensive.
visual: barrier
layout: loop-intro

---
title: shift 10: data wall
subtitle: we are running out of high-quality training data. what happens next?
visual: barrier
layout: loop

**the constraint:**

**all public text on the internet:** ~10-50 trillion tokens.

**already used:** most frontier models trained on majority of it.

**the wall:** by 2026, we will exhaust high-quality human-generated text.

**the shift:**

from "data abundance" to "data scarcity."

**the solutions (all risky):**

- **synthetic data:** ai training on ai output (risks model collapse)
- **private data deals:** reddit, stack overflow selling user content
- **human data farms:** paying people to generate training data
- **multimodal shift:** moving to video, audio, sensor data

**the question:**

if ai trains on ai, does it degrade? (yes, probably.)

---
title: data wall: the evidence
visual: barrier
layout: loop-evidence
loopNumber: 10

**data exhaustion timeline:**

- **2024:** most public text already used
- **2026:** high-quality human data exhausted
- **2030:** reliance on synthetic data inevitable

**synthetic data risks:**

- **model collapse:** ai trained on ai degrades over generations
- **echo chambers:** models reinforcing their own biases
- **loss of diversity:** homogenization of outputs

**data deals:**

- **reddit:** $60M/year deal with google for training data
- **stack overflow:** selling q&a data to ai companies
- **news publishers:** licensing content to openai, google

**alternative sources:**

- **video data:** youtube, tiktok as next frontier
- **sensor data:** iot, wearables, real-world signals
- **human data farms:** paying people to write, label, verify

---
title: shift 11: compute & energy ↔ return of physics
subtitle: ai isn't just software. it's infrastructure.
visual: pulse
layout: loop
dark: true

**the reality:**

ai was sold as infinite scale. but **physics is finite**.

**the constraint:**

training gpt-5 (rumored): **500-1000 GWh** (more than a small country).

global ai energy demand by 2030: **800-1200 TWh** (10% of global electricity).

**the shift:**

from "ai is software" to "ai is infrastructure."

**the bottleneck:**

not ideas. not talent. **energy and chips**.

**why it matters:**

- **geopolitical leverage:** whoever controls energy + chips controls ai
- **climate crisis:** ai growth vs. sustainability—something has to give
- **cost explosion:** training costs doubling every 6 months

**the future:**

ai leadership will be determined by **who can afford to run it**.

---
title: compute: the evidence
visual: pulse
layout: loop-evidence
loopNumber: 11
dark: true

**energy costs:**

- **training gpt-4:** estimated $100M in compute
- **training gpt-5 (rumored):** $500M-$1B
- **data center growth:** microsoft, google, amazon investing $200B+ combined

**infrastructure deals:**

- **microsoft + constellation:** restarting three mile island nuclear reactor
- **google:** 500 MW from renewable sources
- **amazon:** $650M in nuclear-powered data center

**chip wars:**

- **nvidia h100:** $25K-$40K per chip, waitlists of months
- **us export controls:** blocking h100 to china
- **china's response:** huawei ascend chips (domestic alternative)

**cost explosion:**

- **inference costs:** chatgpt $700K/day (2023 estimate)
- **google search + ai:** 10× energy per query
- **training costs:** doubling every 6 months

---
title: summary / the context gap
subtitle: where are we now?
visual: fracture
layout: summary

**the thesis:**

machines have conquered complexity. humans have hit the context wall.

**the 11 shifts:**

**foundation:** energy limits (01), labor displacement (02), sovereignty fracture (03).

**cognition:** reasoning breakthrough (04), infinite memory (05), ai-led discovery (06).

**interface:** vibe coding (07), on-device privacy (08).

**humanity:** machine intimacy (09), data wall (10), compute constraint (11).

**the gap:**

ai is accelerating. humans are buffering.

**the question:**

how do we stay sovereign in a world optimized for machines?

---
title: what now?
subtitle: how to navigate the context gap
visual: compass
layout: summary

**for individuals:**

- **build context filters:** not more data, better curation
- **learn taste, not syntax:** judgment over execution
- **own your ai stack:** privacy, sovereignty, control

**for organizations:**

- **focus on verification, not generation:** the bottleneck is trust
- **invest in reasoning models:** reliability > speed
- **prepare for agentic labor:** redefine roles, not replace people

**for society:**

- **regulate for alignment, not restriction:** enable innovation, prevent catastrophe
- **solve the reliability tax:** $67B problem
- **build human data moats:** clean signal is the new oil

**the mandate:**

do not optimize for the algorithm. **optimize for agency**.

---
title: contributors
subtitle: this report was built by the ai mindset community
visual: network
layout: credits

**core team:**

alex p · ray svitla · sergei khabarov · anca

**research contributors:**

120+ sources integrated from extended industry research

**community:**

ai mindset telegram, substack, workshops

**methodology:**

stress-tested against field signals, enterprise benchmarks, and peer review

**get involved:**

subscribe: https://aimindsetspace.substack.com/
connect: https://t.me/ai_mind_set
website: https://aimindset.org

---
title: end
subtitle: thank you for reading.
visual: fade
layout: end

**this was the context gap.**

**a sovereignty reset for people running their own life.**

**2025 → 2026.**
